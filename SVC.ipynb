{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z2TkU89M0Ar6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are so many columns, the feature selection and model fitting we are about to do can be computationally intensive. Therefore, we'll only consider the first 2000 columns. The next cell will load in that feature data into `X` and the labels into `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hx7ejdgHqgho"
   },
   "outputs": [],
   "source": [
    "X = np.load('X.npy', allow_pickle=True)[:,:2000]\n",
    "y = np.load('y.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlvk_2TcBvD1"
   },
   "source": [
    "Then, you will set aside 25% of the data for evaluating the final model at the end.  Save the result in `Xtr`, `ytr`, `Xts`, and `yts`. \n",
    "\n",
    "Use `sklearn`'s `train_test_split` with shuffling, and you will specify the `random_state = 42`so that your results will match the autograders' results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MXeG3qa2Buci"
   },
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "Xtr, Xts, ytr, yts = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYxW6UM41lvF"
   },
   "source": [
    "Now, you will use 10-fold cross validation (with `sklearn`'s `KFold`, no additional shuffling since you have already shuffled the data) to evaluate model candidates as follows:\n",
    "\n",
    "* First, within each fold, compute the *absolute value* of the correlation coefficient between each column of the feature data and the target variable. (You may use `numpy`'s `corrcoef` function.) Save the results in `score_ft`, which has one entry per column per fold.\n",
    "* Then, iterate over the number of columns to include in the model - the `d` values in `d_list`. In each iteration, you will use the `d` features that had the highest absolute value of correlation coefficient in the model.\n",
    "* You will train an SVC model with a linear kernel, `C=10`, `random_state = 24`, and all other settings at their default values. You will evaluate the model on the validation data and save the accuracy score in `score_val`, which has one entry per `d` value per fold.\n",
    "\n",
    "(Note: in many cases we would standardize the data before fitting an SVC, but we won't do that here.)\n",
    "\n",
    "Write your solution in the `#grade` cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "44anmfCTFowO"
   },
   "outputs": [],
   "source": [
    "d_list = np.arange(1, X.shape[1]+1) \n",
    "nd = len(d_list)\n",
    "nfold = 10\n",
    "\n",
    "score_ft = np.zeros((nd, nfold))\n",
    "score_val = np.zeros((nd,nfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "# Initialize KFold cross-validation\n",
    "kf = KFold(n_splits=nfold)\n",
    "\n",
    "# Iterate over the folds\n",
    "for fold_idx, (train_index, val_index) in enumerate(kf.split(Xtr)):\n",
    "    X_train_fold, y_train_fold = Xtr[train_index], ytr[train_index]\n",
    "    X_val_fold, y_val_fold = Xtr[val_index], ytr[val_index]\n",
    "\n",
    "    # Compute the absolute value of the correlation coefficient for each feature\n",
    "    for i in range(X_train_fold.shape[1]):\n",
    "        feature_data = X_train_fold[:, i]\n",
    "        corr_coef = np.abs(np.corrcoef(feature_data, y_train_fold)[0, 1])\n",
    "        score_ft[i, fold_idx] = corr_coef\n",
    "\n",
    "    # Iterate over the number of features to include in the model\n",
    "    for d in d_list:\n",
    "        # Select the top d features based on the correlation coefficients\n",
    "        top_features_indices = np.argsort(-score_ft[:, fold_idx])[:d]\n",
    "        X_train_fold_d = X_train_fold[:, top_features_indices]\n",
    "        X_val_fold_d = X_val_fold[:, top_features_indices]\n",
    "\n",
    "        # Train the SVC model\n",
    "        model = SVC(kernel='linear', C=10, random_state=24)\n",
    "        model.fit(X_train_fold_d, y_train_fold)\n",
    "\n",
    "        # Evaluate the model on the validation fold\n",
    "        y_pred = model.predict(X_val_fold_d)\n",
    "        score_val[d-1, fold_idx] = accuracy_score(y_val_fold, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `score_val` to find `best_d`, the optimal number of features to include in the model (best mean validation accuracy). (Compute the value - don't hard-code it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Q0WXXzozkwFA"
   },
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "mean_val_accuracy = score_val.mean(axis=1)\n",
    "\n",
    "# Find the index of the maximum mean validation accuracy\n",
    "best_d_index = np.argmax(mean_val_accuracy)\n",
    "\n",
    "# The best number of features, best_d, is the index + 1 since index is 0-based and d starts at 1\n",
    "best_d = d_list[best_d_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, find `best_d_one_se`, the optimal number of features to include according to the one-SE rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9PLIohdnI5nA"
   },
   "outputs": [],
   "source": [
    "#grade (write your code in this cell and DO NOT DELETE THIS LINE)\n",
    "# Compute the standard error for each d value\n",
    "std_val_accuracy = score_val.std(axis=1) / np.sqrt(nfold)\n",
    "\n",
    "# Find the best model (the one with the highest mean validation accuracy)\n",
    "best_mean_accuracy = np.max(mean_val_accuracy)\n",
    "best_model_index = np.argmax(mean_val_accuracy)\n",
    "\n",
    "# Apply the one-SE rule\n",
    "# Find the model within one standard error of the best model\n",
    "# Start from the best model and go backwards to find the simplest model within one SE\n",
    "best_d_one_se_index = np.where(mean_val_accuracy >= best_mean_accuracy - std_val_accuracy[best_model_index])[0][0]\n",
    "best_d_one_se = d_list[best_d_one_se_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Workbook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
